# sweep spec for bart-base-reddit-lora
program: scripts/train.py
name: bart-base-reddit-lora-sweep

method: bayes # {grid | random | bayes}
metric: # what to optimise
  name: eval/loss # must match the key in .evaluate() returns
  goal: minimize

parameters:
  learning_rate:
    min: 0.00001 # 1e-5
    max: 0.001 # 1e-3
    distribution: log_uniform_values
  num_train_epochs:
    values: [4]
  peft_rank:
    values: [128]
  train_sample:
    values: [True]
run_cap: 5 # sweep run limit

project: bart-base-reddit-lora
entity: your-wandb-username

# early_terminate:
#   type: hyperband
#   min_iter: 3